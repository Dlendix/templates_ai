{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Шаблон для решения задач Computer Vision с использованием открытых моделей.\n",
    "Этот шаблон включает:\n",
    "- Загрузку и препроцессинг изображений\n",
    "- Использование предобученных моделей из Hugging Face (например, для классификации, детекции объектов, сегментации)\n",
    "- Обучение/дообучение (fine-tuning) модели\n",
    "- Сохранение и загрузку модели\n",
    "- Простую визуализацию результатов\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from datasets import Dataset as HFDataset # pip install datasets\n",
    "from transformers import (AutoImageProcessor, AutoModelForImageClassification,\n",
    "                          AutoModelForObjectDetection, AutoModelForSemanticSegmentation,\n",
    "                          TrainingArguments, Trainer)\n",
    "import evaluate # pip install evaluate\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. --- Загрузка и препроцессинг изображений ---\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Пример кастомного датасета PyTorch.\n",
    "    Адаптируйте под свой формат данных (пути к файлам, лейблы).\n",
    "    \"\"\"\n",
    "    def __init__(self, image_paths, labels, processor, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.processor = processor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Препроцессинг через image_processor (например, resize, normalize)\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        pixel_values = inputs['pixel_values'].squeeze() # Убираем лишнюю размерность\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": label}\n",
    "\n",
    "# Альтернатива: использование HuggingFace datasets\n",
    "def load_hf_dataset(image_dir, labels_file_or_dict):\n",
    "    \"\"\"\n",
    "    Загрузка датасета через HuggingFace datasets.\n",
    "    image_dir: путь к папке с изображениями\n",
    "    labels_file_or_dict: список или словарь с лейблами\n",
    "    \"\"\"\n",
    "    image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)]\n",
    "    labels = labels_file_or_dict # Адаптируйте под свой формат\n",
    "\n",
    "    def gen():\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            yield {\"image\": Image.open(img_path).convert(\"RGB\"), \"label\": label}\n",
    "\n",
    "    hf_dataset = HFDataset.from_generator(gen)\n",
    "    return hf_dataset\n",
    "\n",
    "# 2. --- Примеры моделей из Hugging Face ---\n",
    "# Замените на конкретные модели под вашу задачу\n",
    "MODEL_NAME_CLASSIFICATION = \"google/vit-base-patch16-224\" # Пример: ViT для классификации\n",
    "MODEL_NAME_OBJECT_DETECTION = \"facebook/detr-resnet-50\" # Пример: DETR для детекции\n",
    "MODEL_NAME_SEGMENTATION = \"nvidia/segformer-b0-finetuned-ade-512-512\" # Пример: SegFormer для сегментации\n",
    "\n",
    "TASK_TYPE = \"classification\" # \"classification\", \"object_detection\", \"segmentation\"\n",
    "\n",
    "def get_model_and_processor(model_name, task_type):\n",
    "    \"\"\"\n",
    "    Загружает модель и препроцессор из Hugging Face.\n",
    "    \"\"\"\n",
    "    image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    if task_type == \"classification\":\n",
    "        model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "    elif task_type == \"object_detection\":\n",
    "        model = AutoModelForObjectDetection.from_pretrained(model_name)\n",
    "    elif task_type == \"segmentation\":\n",
    "        model = AutoModelForSemanticSegmentation.from_pretrained(model_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task_type: {task_type}\")\n",
    "    return model, image_processor\n",
    "\n",
    "# 3. --- Основная функция ---\n",
    "def main():\n",
    "    # --- Настройки ---\n",
    "    model_name = MODEL_NAME_CLASSIFICATION # Выберите нужную модель\n",
    "    task_type = TASK_TYPE\n",
    "    image_dir = \"path/to/your/images\" # Путь к папке с изображениями\n",
    "    labels_file_or_dict = [0, 1, 0, 1, ...] # Адаптируйте под ваш датасет\n",
    "    output_dir = \"./results\"\n",
    "    num_labels = 2 # Количество классов для классификации\n",
    "\n",
    "    # --- Загрузка модели и препроцессора ---\n",
    "    model, image_processor = get_model_and_processor(model_name, task_type)\n",
    "\n",
    "    # --- Загрузка датасета ---\n",
    "    # Вариант 1: через HuggingFace Dataset\n",
    "    hf_dataset = load_hf_dataset(image_dir, labels_file_or_dict)\n",
    "\n",
    "    # Препроцессинг датасета для конкретной задачи\n",
    "    def preprocess(examples):\n",
    "        inputs = image_processor(examples[\"image\"], return_tensors=\"pt\")\n",
    "        # Для классификации\n",
    "        inputs[\"labels\"] = examples[\"label\"]\n",
    "        # Для детекции/сегментации могут потребоваться дополнительные поля\n",
    "        return inputs\n",
    "\n",
    "    processed_dataset = hf_dataset.with_transform(preprocess)\n",
    "\n",
    "    # --- Подготовка метрик ---\n",
    "    metric = evaluate.load(\"accuracy\") # Для классификации\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    # --- Обучение ---\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        remove_unused_columns=False, # Важно для HuggingFace Transformers\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_steps=10,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        report_to=None, # Отключить логгирование в wandb/mlflow\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_dataset, # Разделите на train/val\n",
    "        eval_dataset=processed_dataset, # Используйте отдельный валидационный сет\n",
    "        tokenizer=image_processor, # Иногда требуется\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # trainer.train() # Раскомментируйте для запуска обучения\n",
    "\n",
    "    # --- Сохранение модели ---\n",
    "    # trainer.save_model(f\"{output_dir}/fine_tuned_model\")\n",
    "\n",
    "    # --- Инференс ---\n",
    "    # Загрузка сохраненной модели (или используйте `model` после тренировки)\n",
    "    # loaded_model = AutoModelForImageClassification.from_pretrained(f\"{output_dir}/fine_tuned_model\")\n",
    "    # loaded_processor = AutoImageProcessor.from_pretrained(f\"{output_dir}/fine_tuned_model\")\n",
    "\n",
    "    # Пример инференса\n",
    "    example_image_path = \"path/to/your/example_image.jpg\"\n",
    "    example_image = Image.open(example_image_path).convert(\"RGB\")\n",
    "\n",
    "    inputs = image_processor(example_image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class_idx = logits.argmax(-1).item()\n",
    "        # print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n",
    "\n",
    "    # --- Визуализация (для классификации - просто отображение изображения) ---\n",
    "    plt.imshow(example_image)\n",
    "    plt.title(f\"Predicted: {model.config.id2label[predicted_class_idx]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
